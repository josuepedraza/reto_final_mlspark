{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a29532ae-ebb5-46af-aa32-67c74ee5d936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/30 01:49:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "# %%\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SECOP_MLflow\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884ef18b-b73f-47ae-9fa0-f7518f6a6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca52447b-8ba2-4110-85fc-b3feb81b5439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///opt/mlflow/mlruns/402490040680732574', creation_time=1769736231544, experiment_id='402490040680732574', last_update_time=1769736231544, lifecycle_stage='active', name='secop_prediccion', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name=\"secop_prediccion\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726daa14-ae7b-4537-a8a4-ea8c445a712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 838\n",
      "Test: 162\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/opt/spark-data/processed/secop_ml_ready.parquet\")\n",
    "df = df.withColumnRenamed(\"valor_del_contrato_num\", \"label\") \\\n",
    "       .withColumnRenamed(\"features_pca\", \"features\") \\\n",
    "       .filter(col(\"label\").isNotNull())\n",
    "\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Train: {train.count():,}\")\n",
    "print(f\"Test: {test.count():,}\")\n",
    "\n",
    "# %%\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\"\n",
    ")\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305a3b91-9ae5-48b0-b08d-c9b927a69c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/30 01:38:26 WARN Instrumentation: [9ac2861f] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RMSE: $29,056,073,785.67\n",
      "✓ MAE: $16,319,057,754.43\n",
      "✓ R²: -8333.6628\n",
      "\n",
      "=== EXPERIMENTO 2: Ridge Regression (L2) ===\n",
      "✓ RMSE: $29,056,073,785.62\n",
      "\n",
      "=== EXPERIMENTO 3: Lasso Regression (L1) ===\n",
      "✓ RMSE: $29,056,074,863.70\n",
      "\n",
      "=== EXPERIMENTO 4: ElasticNet (L1 + L2) ===\n",
      "✓ RMSE: $29,056,072,667.81\n",
      "\n",
      "============================================================\n",
      "EXPERIMENTOS COMPLETADOS\n",
      "============================================================\n",
      "✓ 4 experimentos registrados en MLflow\n",
      "✓ Accede a MLflow UI: http://localhost:5000\n",
      "✓ Experimento: secop_prediccion\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Experimento 1\")\n",
    "with mlflow.start_run(run_name=\"baseline_model\"):\n",
    "    # definamos parametros\n",
    "    reg_param = 0.0\n",
    "    elastic_param = 0.0\n",
    "    max_iter = 100\n",
    "    \n",
    "    mlflow.log_param(\"regParam\", reg_param)\n",
    "    mlflow.log_param(\"elasticParam\", elastic_param)\n",
    "    mlflow.log_param(\"maxIaram\", max_iter)\n",
    "    \n",
    "    lr= LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        regParam=reg_param,\n",
    "        elasticNetParam=elastic_param,\n",
    "        maxIter=max_iter\n",
    "    )\n",
    "    \n",
    "    model = lr.fit(train)\n",
    "    \n",
    "    predictions = model.transform(test)\n",
    "    \n",
    "    # Evaluar\n",
    "    rmse = evaluator_rmse.evaluate(predictions)\n",
    "    mae = evaluator_mae.evaluate(predictions)\n",
    "    r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "    # Log de métricas\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Guardar modelo\n",
    "    mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"✓ RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"✓ MAE: ${mae:,.2f}\")\n",
    "    print(f\"✓ R²: {r2:.4f}\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# =====================================\n",
    "# EXPERIMENTO 2: Ridge (L2)\n",
    "# =====================================\n",
    "\n",
    "print(\"\\n=== EXPERIMENTO 2: Ridge Regression (L2) ===\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"ridge_l2_regression\"):\n",
    "    reg_param = 0.1\n",
    "    elastic_param = 0.0  # L2 pure\n",
    "\n",
    "    mlflow.log_param(\"regParam\", reg_param)\n",
    "    mlflow.log_param(\"elasticNetParam\", elastic_param)\n",
    "    mlflow.log_param(\"maxIter\", 100)\n",
    "    mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "\n",
    "    lr = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        regParam=reg_param,\n",
    "        elasticNetParam=elastic_param,\n",
    "        maxIter=100\n",
    "    )\n",
    "\n",
    "    model = lr.fit(train)\n",
    "    predictions = model.transform(test)\n",
    "\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    mae = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(predictions)\n",
    "    r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(predictions)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "    print(f\"✓ RMSE: ${rmse:,.2f}\")\n",
    "\n",
    "# %%\n",
    "# =====================================\n",
    "# EXPERIMENTO 3: Lasso (L1)\n",
    "# =====================================\n",
    "\n",
    "print(\"\\n=== EXPERIMENTO 3: Lasso Regression (L1) ===\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"lasso_l1_regression\"):\n",
    "    reg_param = 0.1\n",
    "    elastic_param = 1.0  # L1 pure\n",
    "\n",
    "    mlflow.log_param(\"regParam\", reg_param)\n",
    "    mlflow.log_param(\"elasticNetParam\", elastic_param)\n",
    "    mlflow.log_param(\"maxIter\", 100)\n",
    "    mlflow.log_param(\"model_type\", \"Lasso\")\n",
    "\n",
    "    lr = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        regParam=reg_param,\n",
    "        elasticNetParam=elastic_param,\n",
    "        maxIter=100\n",
    "    )\n",
    "\n",
    "    model = lr.fit(train)\n",
    "    predictions = model.transform(test)\n",
    "\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    mae = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(predictions)\n",
    "    r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(predictions)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "    print(f\"✓ RMSE: ${rmse:,.2f}\")\n",
    "\n",
    "# %%\n",
    "# =====================================\n",
    "# EXPERIMENTO 4: ElasticNet\n",
    "# =====================================\n",
    "\n",
    "print(\"\\n=== EXPERIMENTO 4: ElasticNet (L1 + L2) ===\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"elasticnet_l1_l2\"):\n",
    "    reg_param = 0.1\n",
    "    elastic_param = 0.5  # Mezcla 50/50\n",
    "\n",
    "    mlflow.log_param(\"regParam\", reg_param)\n",
    "    mlflow.log_param(\"elasticNetParam\", elastic_param)\n",
    "    mlflow.log_param(\"maxIter\", 100)\n",
    "    mlflow.log_param(\"model_type\", \"ElasticNet\")\n",
    "\n",
    "    lr = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        regParam=reg_param,\n",
    "        elasticNetParam=elastic_param,\n",
    "        maxIter=100\n",
    "    )\n",
    "\n",
    "    model = lr.fit(train)\n",
    "    predictions = model.transform(test)\n",
    "\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    mae = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(predictions)\n",
    "    r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(predictions)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "    print(f\"✓ RMSE: ${rmse:,.2f}\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENTOS COMPLETADOS\")\n",
    "print(\"=\"*60)\n",
    "print(\"✓ 4 experimentos registrados en MLflow\")\n",
    "print(f\"✓ Accede a MLflow UI: http://localhost:5000\")\n",
    "print(f\"✓ Experimento: {experiment_name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# %%\n",
    "spark.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f875e9f-dab8-4951-857e-5c59fda97a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/30 01:48:07 INFO mlflow.spark: 'models:/elastic/latest' resolved as 'file:///opt/mlflow/mlruns/402490040680732574/42e2221c257d4694a5621b582fd62aa1/artifacts/model'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo 'elastic' desde el registro...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/30 01:48:07 INFO mlflow.spark: URI 'models:/elastic/latest/sparkml' does not point to the current DFS.\n",
      "2026/01/30 01:48:07 INFO mlflow.spark: File 'models:/elastic/latest/sparkml' not found on DFS. Will attempt to upload the file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo cargado exitosamente\n"
     ]
    }
   ],
   "source": [
    "### Cargar modelos registrados ####\n",
    "\n",
    "import mlflow.spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1. Definir la ruta usando el nombre que elegiste\n",
    "# 'models:/' le dice a MLflow que busque en el registro oficial, no en una carpeta\n",
    "model_name = \"elastic\"\n",
    "model_version = \"latest\" # O puedes poner \"1\", \"2\", etc.\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "# 2. Cargar el modelo como un objeto de Spark ML\n",
    "print(f\"Cargando modelo '{model_name}' desde el registro...\")\n",
    "loaded_model = mlflow.spark.load_model(model_uri)\n",
    "\n",
    "print(\"✓ Modelo cargado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7c47a7-f278-48b0-a41c-0490ad6da438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|          prediction|\n",
      "+--------------------+--------------------+\n",
      "|[1.05511824914886...|1.579372016765363E11|\n",
      "|[2.89965949085992...|-9.83453525732329E10|\n",
      "|[1.91826045058565...|  8.51104667218737E9|\n",
      "|[1.91000751697583...|3.685598427820685...|\n",
      "|[1.91815735697773...|  8.53426230649346E9|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Supongamos que 'df_nuevos_contratos' son datos que acaban de llegar\n",
    "# (Deben haber pasado por el mismo Pipeline de Scaler y PCA)\n",
    "predictions = loaded_model.transform(df)\n",
    "\n",
    "# 4. Mostrar los resultados\n",
    "predictions.select(\"features\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c74833-0523-47e1-86b5-8ec035eff992",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90741cc7-9f4c-4226-ad03-59dd540dcfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimentos disponibles en el servidor:\n",
      " - secop_prediccion\n",
      "✓ Éxito. Mejor Run ID: 42e2221c257d4694a5621b582fd62aa1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# 1. Asegúrate de configurar la URI primero\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "client = MlflowClient()\n",
    "\n",
    "# 2. Listar experimentos para verificar el nombre real\n",
    "print(\"Experimentos disponibles en el servidor:\")\n",
    "for exp in client.search_experiments():\n",
    "    print(f\" - {exp.name}\")\n",
    "\n",
    "# 3. Intentar obtener el experimento con el nombre correcto\n",
    "experiment_name = \"secop_prediccion\" # Verifica si coincide con la lista de arriba\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    raise ValueError(f\"No se encontró el experimento '{experiment_name}'. Revisa la lista de arriba.\")\n",
    "\n",
    "# 4. Si existe, buscar los runs\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "    raise ValueError(f\"El experimento '{experiment_name}' existe pero no tiene ninguna ejecución (runs).\")\n",
    "\n",
    "best_run = runs[0]\n",
    "best_run_id = best_run.info.run_id\n",
    "print(f\"✓ Éxito. Mejor Run ID: {best_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a2a32ef-09e1-494e-a011-92155c88487d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'mejor'.\n",
      "2026/01/30 01:54:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: mejor, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "MODELO REGISTRADO COMO: mejor\n",
      "------------------------------\n",
      "Versión: 1\n",
      "Estado: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'mejor'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# 1. Configuración de acceso (asegúrate de que la URI sea la correcta)\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "\n",
    "# 2. Ruta del modelo usando el ID que ya identificamos\n",
    "# (Asegúrate de que 'best_run_id' esté definido en tu sesión actual)\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "\n",
    "# 3. Registrar con el nombre 'mejor'\n",
    "# Si ya existía uno llamado 'mejor', creará la Versión 2, 3, etc.\n",
    "model_details = mlflow.register_model(model_uri, \"mejor\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"MODELO REGISTRADO COMO: mejor\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Versión: {model_details.version}\")\n",
    "print(f\"Estado: {model_details.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e786f31-1cfb-41eb-b35c-03c9ea155906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
