{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb471172-d96e-45b2-822b-b5513619f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 03: Feature Engineering (Spark ML)\n",
    "\n",
    "**Objetivo**: Construir variables (features) listas para modelado, siguiendo un enfoque incremental:\n",
    "- Primero se valida el flujo con un subset pequeño (1.000–2.000 registros).\n",
    "- Luego se ejecuta el mismo pipeline sobre todo el dataset (≥57.000).\n",
    "\n",
    "**Salida**:\n",
    "- Dataset transformado con columna `features` (Vector) y `label` (objetivo).\n",
    "- Pipeline guardado para reutilización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95492266-b3ef-4845-aecc-b9a67f4d221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, to_timestamp, year, month, dayofmonth,\n",
    "    datediff, regexp_replace, log1p\n",
    ")\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    ")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d550b11c-f53b-48ef-8f9f-1fcf222fa970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/15 01:01:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.0\n",
      "Spark Master: spark://spark-master:7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/15 01:02:02 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"SECOP_FeatureEngineering\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.memory\", \"1g\")\n",
    "         .config(\"spark.executor.cores\", \"1\")\n",
    "         .getOrCreate())\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"Spark Version:\", spark.version)\n",
    "print(\"Spark Master:\", spark.sparkContext.master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34206543-4446-4c66-97ef-6fff8b3440d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo: /opt/spark-data/processed/secop_eda_q4_2025.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros: 60000\n",
      "Columnas: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "parquet_path = \"/opt/spark-data/processed/secop_eda_q4_2025.parquet\"\n",
    "print(\"Leyendo:\", parquet_path)\n",
    "\n",
    "df = spark.read.parquet(parquet_path)\n",
    "print(\"Registros:\", df.count())\n",
    "print(\"Columnas:\", len(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c763b50f-d39b-4377-877b-58942c439ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV registros: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "DEV_N = 2000  \n",
    "df_dev = df.limit(DEV_N)\n",
    "\n",
    "print(\"DEV registros:\", df_dev.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70c9011c-bfe7-48f4-9e75-4b1d37274340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse robusto de fecha (viene tipo: 2025-10-09T00:00:00.000)\n",
    "df_feat = (df_dev\n",
    "           .withColumn(\"fecha_firma_ts\", to_timestamp(col(\"fecha_de_firma\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "           .withColumn(\"anio_firma\", year(col(\"fecha_firma_ts\")))\n",
    "           .withColumn(\"mes_firma\", month(col(\"fecha_firma_ts\")))\n",
    "           .withColumn(\"dia_firma\", dayofmonth(col(\"fecha_firma_ts\")))\n",
    ")\n",
    "\n",
    "# Asegurar valor numérico \n",
    "df_feat = (df_feat\n",
    "           .withColumn(\"valor_del_contrato_clean\",\n",
    "                       regexp_replace(col(\"valor_del_contrato\"), r\"[^0-9,\\.]\", \"\"))\n",
    "           .withColumn(\"valor_del_contrato_num\",\n",
    "                       regexp_replace(col(\"valor_del_contrato_clean\"), \",\", \".\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "# Label (objetivo) para regresión: log(1+valor) para reducir sesgo por outliers\n",
    "df_feat = df_feat.withColumn(\"label\", log1p(col(\"valor_del_contrato_num\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef48791c-cb66-4163-b7e0-44eee62ea788",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = set(df_feat.columns)\n",
    "\n",
    "if (\"fecha_de_inicio_del_contrato\" in cols) and (\"fecha_de_fin_del_contrato\" in cols):\n",
    "    df_feat = (df_feat\n",
    "               .withColumn(\"fecha_inicio_ts\", to_timestamp(col(\"fecha_de_inicio_del_contrato\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "               .withColumn(\"fecha_fin_ts\", to_timestamp(col(\"fecha_de_fin_del_contrato\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "               .withColumn(\"duracion_dias\", datediff(col(\"fecha_fin_ts\"), col(\"fecha_inicio_ts\")))\n",
    "              )\n",
    "else:\n",
    "  \n",
    "    df_feat = df_feat.withColumn(\"duracion_dias\", col(\"valor_del_contrato_num\") * 0)  # 0 como placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77abef71-a9ef-464e-84f6-904338ae8f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categóricas: ['departamento', 'tipo_de_contrato', 'estado_contrato', 'modalidad_de_contratacion']\n",
      "Numéricas: ['anio_firma', 'mes_firma', 'dia_firma', 'duracion_dias']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\n",
    "    \"departamento\",\n",
    "    \"tipo_de_contrato\",\n",
    "    \"estado_contrato\",\n",
    "    \"modalidad_de_contratacion\"\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    \"anio_firma\",\n",
    "    \"mes_firma\",\n",
    "    \"dia_firma\",\n",
    "    \"duracion_dias\"\n",
    "]\n",
    "available_cat = [c for c in categorical_cols if c in df_feat.columns]\n",
    "available_num = [c for c in numeric_cols if c in df_feat.columns]\n",
    "\n",
    "print(\"Categóricas:\", available_cat)\n",
    "print(\"Numéricas:\", available_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7467120-8d9a-41bc-8e41-0350d2c9d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de dropna: 1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_clean = df_feat.dropna(subset=[\"label\"] + available_cat + available_num)\n",
    "print(\"Registros después de dropna:\", df_clean.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b83978b0-f49c-48cb-85bd-49698ed67f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features usadas: ['anio_firma', 'mes_firma', 'dia_firma', 'duracion_dias', 'departamento_ohe', 'tipo_de_contrato_ohe', 'estado_contrato_ohe', 'modalidad_de_contratacion_ohe']\n"
     ]
    }
   ],
   "source": [
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
    "    for c in available_cat\n",
    "]\n",
    "\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=f\"{c}_idx\", outputCol=f\"{c}_ohe\")\n",
    "    for c in available_cat\n",
    "]\n",
    "\n",
    "feature_cols = available_num + [f\"{c}_ohe\" for c in available_cat]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_raw\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\", withMean=False, withStd=True)\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
    "\n",
    "print(\"Features usadas:\", feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22bd16fb-4da5-4ba9-ad82-27c0b123122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando pipeline (DEV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label             |features                                                                                                                                            |\n",
      "+------------------+----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|16.334818714984902|(67,[0,1,2,3,11,38,51,56],[0.0,0.0,2.105792065767273,0.3595536840551413,5.292500109115442,2.4761070103460034,4.411209203389229,2.092911665785985])  |\n",
      "|16.797819844969908|(67,[0,1,2,3,8,38,49,57],[0.0,0.0,2.105792065767273,0.32848114345778345,4.372899895825201,2.4761070103460034,2.2451519194022547,2.4538669099744217])|\n",
      "|17.191595272992377|(67,[0,1,2,3,5,38,50,56],[0.0,0.0,2.105792065767273,1.3449971144284916,3.670271436144235,2.4761070103460034,2.541425645951468,2.092911665785985])   |\n",
      "|16.077273760604726|(67,[0,1,2,3,7,38,49,56],[0.0,0.0,2.105792065767273,0.4039430277656526,6.068624097225035,2.4761070103460034,2.2451519194022547,2.092911665785985])  |\n",
      "|16.780783675579947|(67,[0,1,2,3,4,38,50,56],[0.0,0.0,2.105792065767273,0.43501556836301053,2.275206710539678,2.4761070103460034,2.541425645951468,2.092911665785985])  |\n",
      "+------------------+----------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión vector: 67\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando pipeline (DEV)...\")\n",
    "pipeline_model = pipeline.fit(df_clean)\n",
    "\n",
    "df_transformed = pipeline_model.transform(df_clean)\n",
    "\n",
    "df_transformed.select(\"label\", \"features\").show(5, truncate=False)\n",
    "print(\"Dimensión vector:\", len(df_transformed.select(\"features\").first()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07289172-6083-4fbf-94c8-9495ca668bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL registros: 59125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Repetimos las mismas transformaciones sobre df completo\n",
    "df_full = df\n",
    "\n",
    "df_full_feat = (df_full\n",
    "                .withColumn(\"fecha_firma_ts\", to_timestamp(col(\"fecha_de_firma\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "                .withColumn(\"anio_firma\", year(col(\"fecha_firma_ts\")))\n",
    "                .withColumn(\"mes_firma\", month(col(\"fecha_firma_ts\")))\n",
    "                .withColumn(\"dia_firma\", dayofmonth(col(\"fecha_firma_ts\")))\n",
    "                .withColumn(\"valor_del_contrato_clean\",\n",
    "                            regexp_replace(col(\"valor_del_contrato\"), r\"[^0-9,\\.]\", \"\"))\n",
    "                .withColumn(\"valor_del_contrato_num\",\n",
    "                            regexp_replace(col(\"valor_del_contrato_clean\"), \",\", \".\").cast(\"double\"))\n",
    "                .withColumn(\"label\", log1p(col(\"valor_del_contrato_num\")))\n",
    "               )\n",
    "\n",
    "cols_full = set(df_full_feat.columns)\n",
    "if (\"fecha_de_inicio_del_contrato\" in cols_full) and (\"fecha_de_fin_del_contrato\" in cols_full):\n",
    "    df_full_feat = (df_full_feat\n",
    "                    .withColumn(\"fecha_inicio_ts\", to_timestamp(col(\"fecha_de_inicio_del_contrato\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "                    .withColumn(\"fecha_fin_ts\", to_timestamp(col(\"fecha_de_fin_del_contrato\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS\"))\n",
    "                    .withColumn(\"duracion_dias\", datediff(col(\"fecha_fin_ts\"), col(\"fecha_inicio_ts\")))\n",
    "                   )\n",
    "else:\n",
    "    df_full_feat = df_full_feat.withColumn(\"duracion_dias\", col(\"valor_del_contrato_num\") * 0)\n",
    "\n",
    "# Limpieza mínima\n",
    "df_full_clean = df_full_feat.dropna(subset=[\"label\"] + available_cat + available_num)\n",
    "\n",
    "print(\"FULL registros:\", df_full_clean.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c3d9d4-5806-4329-9557-72df911474a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando pipeline (FULL)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline guardado en: /opt/spark-data/processed/feature_pipeline_q4_2025\n",
      "Dataset features guardado en: /opt/spark-data/processed/secop_features_q4_2025.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando pipeline (FULL)...\")\n",
    "pipeline_model_full = pipeline.fit(df_full_clean)\n",
    "df_full_transformed = pipeline_model_full.transform(df_full_clean)\n",
    "\n",
    "out_dir = \"/opt/spark-data/processed\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "pipeline_path = f\"{out_dir}/feature_pipeline_q4_2025\"\n",
    "features_path = f\"{out_dir}/secop_features_q4_2025.parquet\"\n",
    "\n",
    "# Guardar pipeline y dataset\n",
    "pipeline_model_full.write().overwrite().save(pipeline_path)\n",
    "df_full_transformed.select(\"label\", \"features\").write.mode(\"overwrite\").parquet(features_path)\n",
    "\n",
    "print(\"Pipeline guardado en:\", pipeline_path)\n",
    "print(\"Dataset features guardado en:\", features_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eff8965-9062-44ea-ba3b-bf52e86aba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession finalizada\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"SparkSession finalizada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681808c7-f5b7-49d7-8c92-6645d8057f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
